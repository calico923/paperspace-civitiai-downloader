"""
JSON to CSV Converter

model_metadata_results.json ã‚’ download_history.csv äº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
é‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãã§æ—¢å­˜CSVã«è¿½è¨˜
"""

import json
import argparse
import sys
import os
from typing import List, Dict, Optional
from datetime import datetime

from download_history import DownloadHistoryManager


class JSONToCSVConverter:
    """JSONã‚’CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, history_file: str = "download_history.csv"):
        """
        JSONToCSVConverterã‚’åˆæœŸåŒ–

        Args:
            history_file: å‡ºåŠ›å…ˆCSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.history_manager = DownloadHistoryManager(history_file)
        self.history_file = history_file

    def _format_file_size(self, size_bytes: int) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"

    def _check_duplicate(self, model_id: Optional[int], version_id: Optional[int]) -> bool:
        """
        é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆmodel_id + version_idãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            model_id: ãƒ¢ãƒ‡ãƒ«ID
            version_id: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ID

        Returns:
            bool: é‡è¤‡ã—ã¦ã„ã‚‹å ´åˆTrue
        """
        if not model_id or not version_id:
            return False

        return self.history_manager.check_model_downloaded(model_id, version_id)

    def load_json(self, json_file: str) -> List[Dict]:
        """
        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

        Args:
            json_file: JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            List[Dict]: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        if not os.path.exists(json_file):
            print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_file}")
            return []

        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            print(f"âœ… JSONãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(data)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒª")
            return data if isinstance(data, list) else [data]

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []

    def convert_to_csv(self, metadata_list: List[Dict]) -> int:
        """
        JSONãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«å¤‰æ›ã—ã¦è¿½è¨˜

        Args:
            metadata_list: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

        Returns:
            int: è¿½è¨˜ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
        """
        if not metadata_list:
            print("âš ï¸ å¤‰æ›å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return 0

        added_count = 0
        skipped_count = 0

        print(f"\nğŸ“‹ CSVå¤‰æ›å‡¦ç†ã‚’é–‹å§‹...")
        print(f"{'='*60}")

        for i, metadata in enumerate(metadata_list, 1):
            model_id = metadata.get('model_id')
            version_id = metadata.get('version_id')

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if self._check_duplicate(model_id, version_id):
                print(f"â­ï¸  [{i}/{len(metadata_list)}] ã‚¹ã‚­ãƒƒãƒ—: {metadata.get('file_name')} (é‡è¤‡)")
                skipped_count += 1
                continue

            # CSVã«è¿½è¨˜
            try:
                self.history_manager.record_download(
                    url=metadata.get('civitai_url', ''),
                    model_type=metadata.get('model_type', 'unknown'),
                    filename=metadata.get('file_name', ''),
                    model_id=model_id,
                    version_id=version_id,
                    file_size=metadata.get('file_size'),
                    api_model_type=metadata.get('api_model_type'),
                    lora_subcategory=metadata.get('lora_subcategory')
                )

                print(f"âœ… [{i}/{len(metadata_list)}] è¿½è¨˜å®Œäº†: {metadata.get('file_name')}")
                added_count += 1

            except Exception as e:
                print(f"âŒ [{i}/{len(metadata_list)}] ã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue

        # çµæœã‚µãƒãƒªãƒ¼
        print(f"{'='*60}")
        print(f"\nğŸ“Š å¤‰æ›å®Œäº†:")
        print(f"  âœ… è¿½è¨˜: {added_count}ä»¶")
        print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ— (é‡è¤‡): {skipped_count}ä»¶")
        print(f"  ğŸ“ å‡ºåŠ›: {self.history_file}")

        return added_count


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='JSONå½¢å¼ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«å¤‰æ›',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ä¾‹:
  python json_to_csv.py -i model_metadata_results.json
  python json_to_csv.py -i model_metadata_results.json -o download_history.csv
        '''
    )

    parser.add_argument(
        '-i', '--input',
        required=True,
        help='å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmodel_metadata_results.jsonï¼‰'
    )

    parser.add_argument(
        '-o', '--output',
        default='download_history.csv',
        help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: download_history.csv)'
    )

    args = parser.parse_args()

    try:
        # ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
        converter = JSONToCSVConverter(args.output)

        # JSONãƒ­ãƒ¼ãƒ‰
        metadata_list = converter.load_json(args.input)

        if not metadata_list:
            sys.exit(1)

        # CSVå¤‰æ›ãƒ»è¿½è¨˜
        added_count = converter.convert_to_csv(metadata_list)

        if added_count > 0:
            print(f"\nğŸ‰ æˆåŠŸ: {added_count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜ã—ã¾ã—ãŸ")
            sys.exit(0)
        else:
            print(f"\nâš ï¸  è­¦å‘Š: è¿½è¨˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
            sys.exit(0)

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
