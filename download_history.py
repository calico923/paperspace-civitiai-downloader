"""
Download History Manager Module

ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®è¨˜éŒ²ã¨ç®¡ç†ï¼ˆCSVå½¢å¼å¯¾å¿œï¼‰
"""

import os
import csv
from datetime import datetime
from typing import Optional, List, Dict


class DownloadHistoryManager:
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆCSVå½¢å¼å¯¾å¿œï¼‰"""
    
    # CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼
    CSV_HEADERS = [
        'timestamp', 'model_type', 'url', 'filename', 
        'model_id', 'version_id', 'file_size', 'file_size_bytes'
    ]
    
    def __init__(self, history_file: str):
        """
        DownloadHistoryManagerã‚’åˆæœŸåŒ–
        
        Args:
            history_file: å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.history_file = history_file
        
        # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        history_dir = os.path.dirname(history_file)
        if history_dir and not os.path.exists(history_dir):
            os.makedirs(history_dir, exist_ok=True)
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
        self._ensure_csv_headers()
    
    def _ensure_csv_headers(self):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ˜ãƒƒãƒ€ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¿½åŠ """
        if not os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(self.CSV_HEADERS)
            except Exception as e:
                print(f"âš ï¸  CSVãƒ˜ãƒƒãƒ€ãƒ¼ã®ä½œæˆã«å¤±æ•—: {str(e)}")
    
    def record_download(
        self,
        url: str,
        model_type: str,
        filename: str,
        model_id: Optional[int] = None,
        version_id: Optional[int] = None,
        file_size: Optional[int] = None
    ) -> None:
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸã‚’å±¥æ­´ã«è¨˜éŒ²ï¼ˆCSVå½¢å¼ï¼‰
        
        Args:
            url: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ƒURL
            model_type: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
            filename: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«å
            model_id: ãƒ¢ãƒ‡ãƒ«ID
            version_id: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ID
            file_size: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
        """
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
        size_str = self._format_file_size(file_size) if file_size else "Unknown"
        
        # CSVè¡Œãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        row_data = [
            timestamp,
            model_type,
            url,
            filename,
            str(model_id) if model_id else "",
            str(version_id) if version_id else "",
            size_str,
            str(file_size) if file_size else ""
        ]
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        try:
            with open(self.history_file, 'a', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(row_data)
            print(f"âœ… å±¥æ­´ã«è¨˜éŒ²ã—ã¾ã—ãŸ: {self.history_file}")
        except Exception as e:
            print(f"âš ï¸  å±¥æ­´ã®è¨˜éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def _format_file_size(self, size_bytes: int) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
        
        Args:
            size_bytes: ãƒã‚¤ãƒˆå˜ä½ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            
        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º (ä¾‹: "1.23 GB")
        """
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"
    
    def _remove_duplicates(self, downloads: List[Dict]) -> List[Dict]:
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‹ã‚‰é‡è¤‡ã‚’é™¤å»ï¼ˆmodel_id + version_idã§åˆ¤å®šï¼‰
        
        Args:
            downloads: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            List[Dict]: é‡è¤‡é™¤å»ã•ã‚ŒãŸãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®ãƒªã‚¹ãƒˆ
        """
        seen = set()
        unique_downloads = []
        
        for download in downloads:
            model_id = download.get('model_id', '')
            version_id = download.get('version_id', '')
            
            # model_id + version_idã®çµ„ã¿åˆã‚ã›ã§ä¸€æ„æ€§ã‚’åˆ¤å®š
            key = f"{model_id}_{version_id}"
            
            if key not in seen and model_id and version_id:
                seen.add(key)
                unique_downloads.append(download)
            elif not model_id or not version_id:
                # model_idã‚„version_idãŒç©ºã®å ´åˆã¯URLã§åˆ¤å®š
                url = download.get('url', '')
                if url and url not in seen:
                    seen.add(url)
                    unique_downloads.append(download)
        
        return unique_downloads
    
    def get_recent_downloads(self, count: int = 10) -> List[Dict]:
        """
        æœ€è¿‘ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‚’å–å¾—ï¼ˆCSVå½¢å¼ï¼‰
        
        Args:
            count: å–å¾—ã™ã‚‹å±¥æ­´ã®æ•°
            
        Returns:
            List[Dict]: æœ€è¿‘ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®ãƒªã‚¹ãƒˆ
        """
        if not os.path.exists(self.history_file):
            return []
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            # æœ€å¾Œã®countè¡Œã‚’è¿”ã™
            return rows[-count:] if len(rows) > count else rows
        except Exception as e:
            print(f"å±¥æ­´ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
            return []
    
    def get_all_downloads(self, remove_duplicates: bool = True) -> List[Dict]:
        """
        å…¨ã¦ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‚’å–å¾—
        
        Args:
            remove_duplicates: é‡è¤‡ã‚’é™¤å»ã™ã‚‹ã‹ã©ã†ã‹
        
        Returns:
            List[Dict]: å…¨ã¦ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®ãƒªã‚¹ãƒˆ
        """
        if not os.path.exists(self.history_file):
            return []
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                downloads = list(reader)
            
            if remove_duplicates:
                return self._remove_duplicates(downloads)
            return downloads
        except Exception as e:
            print(f"å±¥æ­´ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
            return []
    
    def get_downloads_by_type(self, model_type: str) -> List[Dict]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‚’å–å¾—
        
        Args:
            model_type: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
            
        Returns:
            List[Dict]: è©²å½“ã™ã‚‹ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®ãƒªã‚¹ãƒˆ
        """
        all_downloads = self.get_all_downloads()
        return [download for download in all_downloads if download.get('model_type') == model_type]
    
    def check_url_downloaded(self, url: str) -> bool:
        """
        URLãŒæ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            url: ãƒã‚§ãƒƒã‚¯ã™ã‚‹URL
            
        Returns:
            bool: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆTrue
        """
        all_downloads = self.get_all_downloads(remove_duplicates=False)
        return any(download.get('url') == url for download in all_downloads)
    
    def check_model_downloaded(self, model_id: int, version_id: int) -> bool:
        """
        ãƒ¢ãƒ‡ãƒ«ï¼ˆmodel_id + version_idï¼‰ãŒæ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            model_id: ãƒ¢ãƒ‡ãƒ«ID
            version_id: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ID
            
        Returns:
            bool: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆTrue
        """
        all_downloads = self.get_all_downloads(remove_duplicates=False)
        for download in all_downloads:
            if (download.get('model_id') == str(model_id) and 
                download.get('version_id') == str(version_id)):
                return True
        return False
    
    def get_download_info(self, url: str) -> Optional[Dict]:
        """
        æŒ‡å®šã•ã‚ŒãŸURLã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
        
        Args:
            url: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL
            
        Returns:
            Optional[Dict]: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æƒ…å ±ã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
        """
        all_downloads = self.get_all_downloads()
        for download in all_downloads:
            if download.get('url') == url:
                return download
        return None
    
    def list_downloads_for_redownload(self) -> List[Dict]:
        """
        å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªå±¥æ­´ã‚’å–å¾—ï¼ˆURLã¨typeã®ã¿ï¼‰
        
        Returns:
            List[Dict]: å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        all_downloads = self.get_all_downloads()
        return [
            {
                'url': download.get('url'),
                'model_type': download.get('model_type'),
                'filename': download.get('filename'),
                'timestamp': download.get('timestamp')
            }
            for download in all_downloads
        ]
    
    def clean_duplicates(self) -> int:
        """
        å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é‡è¤‡ã‚’é™¤å»ã—ã¦æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Returns:
            int: é™¤å»ã•ã‚ŒãŸé‡è¤‡ã®æ•°
        """
        if not os.path.exists(self.history_file):
            return 0
        
        try:
            # å…ƒã®å±¥æ­´ã‚’èª­ã¿è¾¼ã¿
            with open(self.history_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                original_downloads = list(reader)
            
            # é‡è¤‡é™¤å»
            unique_downloads = self._remove_duplicates(original_downloads)
            
            # é‡è¤‡æ•°è¨ˆç®—
            duplicates_removed = len(original_downloads) - len(unique_downloads)
            
            if duplicates_removed > 0:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                backup_file = self.history_file + '.backup'
                with open(backup_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(self.CSV_HEADERS)
                    for download in original_downloads:
                        writer.writerow([download.get(header, '') for header in self.CSV_HEADERS])
                
                # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
                with open(self.history_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(self.CSV_HEADERS)
                    for download in unique_downloads:
                        writer.writerow([download.get(header, '') for header in self.CSV_HEADERS])
                
                print(f"âœ… é‡è¤‡é™¤å»å®Œäº†: {duplicates_removed}ä»¶ã®é‡è¤‡ã‚’é™¤å»")
                print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: {backup_file}")
            else:
                print("âœ… é‡è¤‡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            return duplicates_removed
            
        except Exception as e:
            print(f"âŒ é‡è¤‡é™¤å»ã«å¤±æ•—: {str(e)}")
            return 0


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆ
    manager = DownloadHistoryManager("./test_history.txt")
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è¨˜éŒ²ã®ãƒ†ã‚¹ãƒˆ
    manager.record_download(
        url="https://civitai.com/models/649516?modelVersionId=726676",
        model_type="lora",
        filename="test_model.safetensors",
        model_id=649516,
        version_id=726676,
        file_size=123456789
    )
    
    # æœ€è¿‘ã®å±¥æ­´ã‚’è¡¨ç¤º
    print("\næœ€è¿‘ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:")
    for entry in manager.get_recent_downloads(5):
        print(f"  {entry}")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    is_downloaded = manager.check_url_downloaded("https://civitai.com/models/649516?modelVersionId=726676")
    print(f"\nURL already downloaded: {is_downloaded}")

