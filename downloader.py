"""
Civitai Model Downloader

Civitai.comã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ComfyUI-Lora-Managerã®å®Ÿè£…ã‚’å‚è€ƒã«ç°¡ç•¥åŒ–
"""

import asyncio
import aiohttp
import os
import sys
import argparse
from typing import Optional, Dict, Tuple, List
from datetime import datetime
import time

from url_parser import CivitaiURLParser
from config_manager import ConfigManager
from download_history import DownloadHistoryManager
from model_type_classifier import ModelTypeClassifier


class CivitaiDownloader:
    """Civitaiã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: ConfigManager):
        """
        CivitaiDownloaderã‚’åˆæœŸåŒ–
        
        Args:
            config: è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        """
        self.config = config
        self.api_key = config.get_api_key()
        self.base_url = "https://civitai.com/api/v1"
        self.session: Optional[aiohttp.ClientSession] = None
        self.chunk_size = 4 * 1024 * 1024  # 4MB chunks
        self.type_classifier = ModelTypeClassifier()
    
    async def __aenter__(self):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼"""
        await self._create_session()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®çµ‚äº†"""
        await self.close()
    
    async def _create_session(self):
        """HTTP sessionã‚’ä½œæˆ"""
        connector = aiohttp.TCPConnector(
            ssl=True,
            limit=8,
            ttl_dns_cache=300,
            force_close=False,
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(
            total=None,
            connect=60,
            sock_read=300
        )
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout
        )
    
    async def close(self):
        """HTTP sessionã‚’é–‰ã˜ã‚‹"""
        if self.session:
            await self.session.close()
    
    def _get_headers(self, use_auth: bool = True) -> Dict[str, str]:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—"""
        headers = {
            'User-Agent': 'Civitai-Downloader/1.0'
        }
        
        if use_auth and self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'
            headers['Content-Type'] = 'application/json'
        
        return headers
    
    async def get_model_version_info(
        self,
        model_id: Optional[int] = None,
        version_id: Optional[int] = None
    ) -> Optional[Dict]:
        """
        ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
        
        Args:
            model_id: ãƒ¢ãƒ‡ãƒ«ID
            version_id: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ID
            
        Returns:
            Dict: ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã€å–å¾—å¤±æ•—æ™‚ã¯None
        """
        try:
            # version_idãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç›´æ¥å–å¾—
            if version_id:
                url = f"{self.base_url}/model-versions/{version_id}"
                async with self.session.get(url, headers=self._get_headers()) as response:
                    if response.status == 200:
                        version_info = await response.json()
                        
                        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚‚å–å¾—
                        model_id_from_version = version_info.get('modelId')
                        if model_id_from_version:
                            model_url = f"{self.base_url}/models/{model_id_from_version}"
                            async with self.session.get(model_url, headers=self._get_headers()) as model_response:
                                if model_response.status == 200:
                                    model_data = await model_response.json()
                                    if 'model' not in version_info:
                                        version_info['model'] = {}
                                    version_info['model']['description'] = model_data.get('description')
                                    version_info['model']['tags'] = model_data.get('tags', [])
                                    version_info['creator'] = model_data.get('creator')
                        
                        return version_info
                    elif response.status == 401:
                        print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™")
                        return None
                    elif response.status == 404:
                        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (Version ID: {version_id})")
                        return None
                    else:
                        print(f"âŒ APIã‚¨ãƒ©ãƒ¼ (Status: {response.status})")
                        return None
            
            # model_idã®ã¿ã®å ´åˆ
            elif model_id:
                url = f"{self.base_url}/models/{model_id}"
                async with self.session.get(url, headers=self._get_headers()) as response:
                    if response.status == 200:
                        model_data = await response.json()
                        
                        # æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—
                        model_versions = model_data.get('modelVersions', [])
                        if not model_versions:
                            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                            return None
                        
                        latest_version = model_versions[0]
                        version_id = latest_version.get('id')
                        
                        # è©³ç´°ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
                        return await self.get_model_version_info(version_id=version_id)
                    else:
                        print(f"âŒ ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—ã«å¤±æ•— (Status: {response.status})")
                        return None
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    async def download_file(
        self,
        url: str,
        save_path: str,
        use_auth: bool = True
    ) -> Tuple[bool, Optional[str]]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Args:
            url: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL
            save_path: ä¿å­˜å…ˆãƒ‘ã‚¹
            use_auth: èªè¨¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            
        Returns:
            Tuple[bool, Optional[str]]: (æˆåŠŸ/å¤±æ•—, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        """
        part_path = save_path + '.part'
        
        # ãƒªã‚¸ãƒ¥ãƒ¼ãƒ ç”¨: æ—¢å­˜ã®.partãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
        resume_offset = 0
        if os.path.exists(part_path):
            resume_offset = os.path.getsize(part_path)
            print(f"ğŸ“¥ ãƒ¬ã‚¸ãƒ¥ãƒ¼ãƒ : {resume_offset:,} ãƒã‚¤ãƒˆã‹ã‚‰å†é–‹")
        
        try:
            headers = self._get_headers(use_auth)
            
            # Range headerã§ãƒªã‚¸ãƒ¥ãƒ¼ãƒ ã‚’ã‚µãƒãƒ¼ãƒˆ
            if resume_offset > 0:
                headers['Range'] = f'bytes={resume_offset}-'
            
            async with self.session.get(url, headers=headers, allow_redirects=True) as response:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
                if response.status == 401:
                    return False, "èªè¨¼ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯å¿…è¦ã§ã™"
                elif response.status == 403:
                    return False, "ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦: Early Accessãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                elif response.status == 404:
                    return False, "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                elif response.status not in (200, 206):
                    return False, f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— (Status: {response.status})"
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
                total_size = int(response.headers.get('content-length', 0))
                if response.status == 206:
                    total_size += resume_offset
                
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹
                mode = 'ab' if resume_offset > 0 else 'wb'
                downloaded = resume_offset
                start_time = time.time()
                last_print_time = start_time
                
                print(f"ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {os.path.basename(save_path)}")
                print(f"ğŸ“¦ ã‚µã‚¤ã‚º: {self._format_size(total_size)}")
                
                with open(part_path, mode) as f:
                    async for chunk in response.content.iter_chunked(self.chunk_size):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            # é€²æ—è¡¨ç¤ºï¼ˆ1ç§’ã”ã¨ï¼‰
                            current_time = time.time()
                            if current_time - last_print_time >= 1.0:
                                elapsed = current_time - start_time
                                speed = (downloaded - resume_offset) / elapsed if elapsed > 0 else 0
                                percent = (downloaded / total_size * 100) if total_size > 0 else 0
                                
                                print(f"â³ {percent:.1f}% | {self._format_size(downloaded)}/{self._format_size(total_size)} | {self._format_size(speed)}/s", end='\r')
                                last_print_time = current_time
                
                # å®Œäº†ã—ãŸã‚‰.partã‚’å‰Šé™¤ã—ã¦ãƒªãƒãƒ¼ãƒ 
                if os.path.exists(save_path):
                    os.remove(save_path)
                os.rename(part_path, save_path)
                
                elapsed = time.time() - start_time
                avg_speed = (downloaded - resume_offset) / elapsed if elapsed > 0 else 0
                
                print(f"\nâœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†!")
                print(f"â±ï¸  æ™‚é–“: {elapsed:.1f}ç§’ | å¹³å‡é€Ÿåº¦: {self._format_size(avg_speed)}/s")
                
                return True, None
                
        except Exception as e:
            return False, f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _format_size(self, size_bytes: float) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"
    
    async def download_model(
        self,
        url: str,
        model_type: Optional[str] = None
    ) -> Tuple[bool, Optional[str], Optional[Dict]]:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Args:
            url: Civitai URL
            model_type: ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— ('lora', 'checkpoint', 'embedding') - Noneã®å ´åˆã¯è‡ªå‹•åˆ¤å®š
            
        Returns:
            Tuple[bool, Optional[str], Optional[Dict]]: (æˆåŠŸ/å¤±æ•—, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æƒ…å ±)
        """
        print(f"\n{'='*60}")
        print(f"ğŸš€ Civitai Model Downloader")
        print(f"{'='*60}")
        print(f"ğŸ“ URL: {url}")
        print(f"ğŸ“‚ Type: {model_type or 'è‡ªå‹•åˆ¤å®š'}")
        print(f"{'='*60}\n")
        
        # URLã‚’è§£æ
        try:
            model_id, version_id = CivitaiURLParser.parse_url(url)
            print(f"ğŸ” Model ID: {model_id}, Version ID: {version_id}")
        except ValueError as e:
            return False, str(e), None
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        print(f"ğŸ“¡ ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—ä¸­...")
        version_info = await self.get_model_version_info(model_id, version_id)
        
        if not version_info:
            return False, "ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", None
        
        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®è‡ªå‹•åˆ¤å®šã¾ãŸã¯æ¤œè¨¼
        if model_type is None:
            # è‡ªå‹•åˆ¤å®š
            print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤å®šä¸­...")
            detected_type, reason = self.type_classifier.classify_from_metadata(version_info)
            
            if detected_type is None:
                return False, f"ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®è‡ªå‹•åˆ¤å®šã«å¤±æ•—: {reason}", None
            
            model_type = detected_type
            print(f"âœ… è‡ªå‹•åˆ¤å®šçµæœ: {model_type} ({reason})")
        else:
            # æ‰‹å‹•æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã®æ¤œè¨¼
            actual_type = version_info.get('model', {}).get('type', '').lower()
            
            # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°
            type_mapping = {
                'lora': ['lora', 'locon', 'loha'],
                'checkpoint': ['checkpoint'],
                'embedding': ['textualinversion']
            }
            
            valid_types = type_mapping.get(model_type, [])
            if actual_type not in valid_types:
                return False, f"ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚æœŸå¾…: {model_type}, å®Ÿéš›: {actual_type}", None
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«å: {version_info.get('name', 'Unknown')}")
        print(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: {version_info.get('baseModel', 'Unknown')}")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’å–å¾—
        files = version_info.get('files', [])
        primary_file = next((f for f in files if f.get('primary') and f.get('type') == 'Model'), None)
        
        if not primary_file:
            return False, "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", None
        
        download_url = primary_file.get('downloadUrl')
        filename = primary_file.get('name')
        file_size = primary_file.get('sizeKB', 0) * 1024
        
        if not download_url or not filename:
            return False, "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", None
        
        # ä¿å­˜å…ˆãƒ‘ã‚¹
        download_path = self.config.get_download_path(model_type)
        save_path = os.path.join(download_path, filename)
        
        print(f"ğŸ’¾ ä¿å­˜å…ˆ: {save_path}")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
        success, error = await self.download_file(download_url, save_path, use_auth=True)
        
        if not success:
            return False, error, None
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æƒ…å ±ã‚’è¿”ã™
        download_info = {
            'url': url,
            'model_type': model_type,
            'filename': filename,
            'save_path': save_path,
            'model_id': model_id,
            'version_id': version_id or version_info.get('id'),
            'file_size': file_size
        }
        
        return True, None, download_info


async def redownload_all(downloads: List[Dict], config: ConfigManager, force: bool = False):
    """
    å…¨ä»¶å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
    
    Args:
        downloads: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã®ãƒªã‚¹ãƒˆ
        config: è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        force: å¼·åˆ¶ä¸Šæ›¸ããƒ•ãƒ©ã‚°
    """
    total = len(downloads)
    success_count = 0
    error_count = 0
    
    print(f"\nğŸš€ å…¨ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {total}ä»¶")
    print(f"{'='*60}")
    
    async with CivitaiDownloader(config) as downloader:
        for i, download in enumerate(downloads, 1):
            url = download.get('url')
            model_type = download.get('model_type')
            filename = download.get('filename')
            
            print(f"\nğŸ“¥ [{i}/{total}] {filename}")
            print(f"ğŸ”— URL: {url}")
            print(f"ğŸ“‚ Type: {model_type}")
            print(f"{'-'*40}")
            
            try:
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆforceãŒFalseã®å ´åˆã®ã¿ï¼‰
                if not force:
                    # URLã‚’è§£æã—ã¦model_idã¨version_idã‚’å–å¾—
                    try:
                        model_id, version_id = CivitaiURLParser.parse_url(url)
                        # å±¥æ­´ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å–å¾—
                        history_manager = DownloadHistoryManager(config.get_history_file())
                        model_duplicate = history_manager.check_model_downloaded(model_id, version_id)
                        if model_duplicate:
                            print(f"âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿")
                            continue
                    except ValueError:
                        pass
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                success, error, download_info = await downloader.download_model(url, model_type)
                
                if success:
                    print(f"âœ… æˆåŠŸ: {filename}")
                    success_count += 1
                else:
                    print(f"âŒ å¤±æ•—: {error}")
                    error_count += 1
                    
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                error_count += 1
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print(f"ğŸ‰ å…¨ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†!")
    print(f"{'='*60}")
    print(f"âœ… æˆåŠŸ: {success_count}ä»¶")
    print(f"âŒ å¤±æ•—: {error_count}ä»¶")
    print(f"ğŸ“Š åˆè¨ˆ: {total}ä»¶")


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='Civitai.comã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ä¾‹:
  python downloader.py -u "https://civitai.com/models/649516?modelVersionId=726676"  # è‡ªå‹•åˆ¤å®š
  python downloader.py -u "https://civitai.com/models/649516?modelVersionId=726676" -t lora  # æ‰‹å‹•æŒ‡å®š
  python downloader.py -u "https://civitai.com/models/123456" -t checkpoint
  python downloader.py -u "https://civitai.com/models/789012" -t embedding -c custom_config.json
  python downloader.py -u "https://civitai.com/models/123456" -y  # éå¯¾è©±å‹ï¼ˆipynbå¯¾å¿œï¼‰
        '''
    )
    
    parser.add_argument(
        '-u', '--url',
        help='Civitai ãƒ¢ãƒ‡ãƒ«URL'
    )
    
    parser.add_argument(
        '-t', '--type',
        choices=['lora', 'checkpoint', 'embedding'],
        help='ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è‡ªå‹•åˆ¤å®šï¼‰'
    )
    
    parser.add_argument(
        '-c', '--config',
        default='config.json',
        help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.json)'
    )
    
    parser.add_argument(
        '--list-history',
        action='store_true',
        help='ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‚’è¡¨ç¤º'
    )
    
    parser.add_argument(
        '--redownload',
        type=int,
        metavar='INDEX',
        help='å±¥æ­´ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰'
    )
    
    parser.add_argument(
        '--redownload-url',
        nargs='?',
        const='all',
        help='æŒ‡å®šã•ã‚ŒãŸURLã‚’å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå±¥æ­´ã‹ã‚‰è‡ªå‹•æ¤œå‡ºï¼‰ã€‚å¼•æ•°ãªã—ã®å ´åˆã¯å…¨ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸Šæ›¸ãã‚’å¼·åˆ¶ï¼ˆç¢ºèªãªã—ï¼‰'
    )
    
    parser.add_argument(
        '-y', '--yes',
        action='store_true',
        help='ã™ã¹ã¦ã®ç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆéå¯¾è©±å‹ãƒ¢ãƒ¼ãƒ‰ï¼‰'
    )
    
    parser.add_argument(
        '--clean-duplicates',
        action='store_true',
        help='å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é‡è¤‡ã‚’é™¤å»'
    )
    
    args = parser.parse_args()
    
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        print(f"ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {args.config}")
        config = ConfigManager(args.config)
        
        if not config.validate():
            print("âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
        
        # å±¥æ­´ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        history_manager = DownloadHistoryManager(config.get_history_file())
        
        # é‡è¤‡é™¤å»
        if args.clean_duplicates:
            print(f"\n{'='*60}")
            print(f"ğŸ§¹ å±¥æ­´ã®é‡è¤‡é™¤å»")
            print(f"{'='*60}")
            
            duplicates_removed = history_manager.clean_duplicates()
            if duplicates_removed > 0:
                print(f"âœ… {duplicates_removed}ä»¶ã®é‡è¤‡ã‚’é™¤å»ã—ã¾ã—ãŸ")
            else:
                print("âœ… é‡è¤‡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            sys.exit(0)
        
        # å±¥æ­´è¡¨ç¤º
        if args.list_history:
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å±¥æ­´")
            print(f"{'='*60}")
            
            downloads = history_manager.get_all_downloads(remove_duplicates=True)
            if not downloads:
                print("å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
                sys.exit(0)
            
            print(f"ğŸ“Š è¡¨ç¤ºä»¶æ•°: {len(downloads)}ä»¶ï¼ˆé‡è¤‡é™¤å»æ¸ˆã¿ï¼‰")
            print()
            
            for i, download in enumerate(downloads, 1):
                print(f"{i:2d}. [{download.get('timestamp', 'Unknown')}]")
                print(f"    Type: {download.get('model_type', 'Unknown')}")
                print(f"    URL: {download.get('url', 'Unknown')}")
                print(f"    File: {download.get('filename', 'Unknown')}")
                print(f"    Size: {download.get('file_size', 'Unknown')}")
                print()
            
            print(f"ğŸ’¡ å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: --redownload <INDEX> ã¾ãŸã¯ --redownload-url <URL>")
            print(f"ğŸ’¡ é‡è¤‡é™¤å»: --clean-duplicates")
            sys.exit(0)
        
        # å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æŒ‡å®šï¼‰
        if args.redownload is not None:
            downloads = history_manager.get_all_downloads(remove_duplicates=True)
            if not downloads:
                print("âŒ å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
                sys.exit(1)
            
            if args.redownload < 1 or args.redownload > len(downloads):
                print(f"âŒ ç„¡åŠ¹ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {args.redownload} (1-{len(downloads)})")
                sys.exit(1)
            
            download = downloads[args.redownload - 1]
            url = download.get('url')
            model_type = download.get('model_type')
            
            print(f"ğŸ”„ å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {url}")
            print(f"ğŸ“‚ Type: {model_type}")
            
            # é€šå¸¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã«ç§»è¡Œ
            args.url = url
            args.type = model_type
        
        # å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆURLæŒ‡å®šï¼‰
        elif args.redownload_url:
            if args.redownload_url == 'all':
                # å…¨ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                print(f"\n{'='*60}")
                print(f"ğŸ”„ å…¨ä»¶å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                print(f"{'='*60}")
                
                downloads = history_manager.get_all_downloads(remove_duplicates=True)
                if not downloads:
                    print("âŒ å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
                    sys.exit(1)
                
                print(f"ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡: {len(downloads)}ä»¶")
                
                # ç¢ºèª
                if not args.force and not args.yes:
                    choice = input("å…¨ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
                    if choice.lower() != 'y':
                        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                        sys.exit(0)
                
                # å…¨ä»¶ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                await redownload_all(downloads, config, args.force)
                sys.exit(0)
            else:
                # å¼•æ•°ãŒæ•°å€¤ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
                try:
                    index = int(args.redownload_url)
                    # æ•°å€¤ã®å ´åˆã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æŒ‡å®šã¨ã—ã¦å‡¦ç†
                    downloads = history_manager.get_all_downloads(remove_duplicates=True)
                    if not downloads:
                        print("âŒ å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
                        sys.exit(1)
                    
                    if index < 1 or index > len(downloads):
                        print(f"âŒ ç„¡åŠ¹ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {index} (1-{len(downloads)})")
                        sys.exit(1)
                    
                    download = downloads[index - 1]
                    url = download.get('url')
                    model_type = download.get('model_type')
                    
                    print(f"ğŸ”„ å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {url}")
                    print(f"ğŸ“‚ Type: {model_type}")
                    
                    # é€šå¸¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã«ç§»è¡Œ
                    args.url = url
                    args.type = model_type
                    
                except ValueError:
                    # æ•°å€¤ã§ãªã„å ´åˆã¯URLã¨ã—ã¦å‡¦ç†
                    download_info = history_manager.get_download_info(args.redownload_url)
                    if not download_info:
                        print(f"âŒ å±¥æ­´ã«URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.redownload_url}")
                        sys.exit(1)
                    
                    url = download_info.get('url')
                    model_type = download_info.get('model_type')
                    
                    print(f"ğŸ”„ å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {url}")
                    print(f"ğŸ“‚ Type: {model_type}")
                    
                    # é€šå¸¸ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã«ç§»è¡Œ
                    args.url = url
                    args.type = model_type
        
        # URLãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if not args.url:
            print("âŒ URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            print("ğŸ’¡ å±¥æ­´è¡¨ç¤º: --list-history")
            print("ğŸ’¡ å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: --redownload <INDEX> ã¾ãŸã¯ --redownload-url <URL>")
            print("ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã¯è‡ªå‹•åˆ¤å®šã•ã‚Œã¾ã™ï¼ˆ-t ã§æ‰‹å‹•æŒ‡å®šã‚‚å¯èƒ½ï¼‰")
            sys.exit(1)
        
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆURLã¨model_id+version_idã®ä¸¡æ–¹ã§ãƒã‚§ãƒƒã‚¯ï¼‰
        url_duplicate = history_manager.check_url_downloaded(args.url)
        
        # URLã‚’è§£æã—ã¦model_idã¨version_idã‚’å–å¾—
        try:
            model_id, version_id = CivitaiURLParser.parse_url(args.url)
            model_duplicate = history_manager.check_model_downloaded(model_id, version_id)
        except ValueError:
            model_duplicate = False
        
        if (url_duplicate or model_duplicate) and not args.force and not args.yes:
            print(f"âš ï¸  ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™:")
            if url_duplicate:
                print(f"   URL: {args.url}")
            if model_duplicate:
                print(f"   Model ID: {model_id}, Version ID: {version_id}")
            choice = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
            if choice.lower() != 'y':
                print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                sys.exit(0)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼å®Ÿè¡Œ
        async with CivitaiDownloader(config) as downloader:
            success, error, download_info = await downloader.download_model(args.url, args.type)
            
            if success and download_info:
                print(f"\n{'='*60}")
                print(f"ğŸ‰ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ!")
                print(f"{'='*60}")
                
                # å±¥æ­´ã«è¨˜éŒ²
                history_manager.record_download(
                    url=download_info['url'],
                    model_type=download_info['model_type'],
                    filename=download_info['filename'],
                    model_id=download_info['model_id'],
                    version_id=download_info['version_id'],
                    file_size=download_info.get('file_size')
                )
                
                sys.exit(0)
            else:
                print(f"\n{'='*60}")
                print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
                print(f"{'='*60}")
                print(f"ã‚¨ãƒ©ãƒ¼: {error}")
                sys.exit(1)
    
    except FileNotFoundError as e:
        print(f"\nâŒ {str(e)}")
        sys.exit(1)
    except ValueError as e:
        print(f"\nâŒ {str(e)}")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())

